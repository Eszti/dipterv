{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import copy\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conf\n",
    "langs = ['eng', 'deu', 'hun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read embeddings and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = '/home/eszti/projects/dipterv/notebooks/panlex/train_try/t0'\n",
    "\n",
    "d_models = dict()\n",
    "for l in langs:\n",
    "    fn = os.path.join(fold, '{}.vec'.format(l))\n",
    "    model = KeyedVectors.load_word2vec_format(fn, binary=False)\n",
    "    model.syn0 /= np.sqrt((model.syn0**2).sum(1))[:, None]\n",
    "    d_models[l] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 300)\n",
      "['kutya', 'macska', 'nap', 'hold']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "print(d_models['hun'].syn0.shape)\n",
    "print(d_models['hun'].index2word)\n",
    "\n",
    "np.linalg.norm(d_models['hun']['kutya'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read words pairs from tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_word_pairs_tsv(fn, id1, id2):\n",
    "    with open(fn) as f:\n",
    "        lines = f.readlines()\n",
    "        data = [(line.split()[id1], line.split()[id2]) for i, line in enumerate(lines) if i > 0]\n",
    "    return data\n",
    "\n",
    "def wp_list_2_dict(lang_pair, wp_l):\n",
    "    l1 = lang_pair[0]\n",
    "    l2 = lang_pair[1]\n",
    "    l12 = dict()\n",
    "    l21 = dict()\n",
    "    for (w1, w2) in wp_l:\n",
    "        if w1 not in l12:\n",
    "            l12[w1] = [w2]\n",
    "        else:\n",
    "            l12[w1] += w2\n",
    "        if w2 not in l21:\n",
    "            l21[w2] = [w1]\n",
    "        else:\n",
    "            l21[w2] += w1\n",
    "    return l12, l21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = '/home/eszti/projects/dipterv/notebooks/panlex/train_try/t0'\n",
    "id1 = 2\n",
    "id2 = 3\n",
    "# Dict for word pairs\n",
    "d_wps = dict()\n",
    "done = set()\n",
    "for lang1 in langs:\n",
    "    for lang2 in langs:\n",
    "        lang_pair = tuple(sorted([lang1, lang2]))\n",
    "        if lang1 == lang2 or lang_pair in done:\n",
    "            continue\n",
    "        done.add(lang_pair)\n",
    "        l1 = lang_pair[0]\n",
    "        l2 = lang_pair[1]\n",
    "        fn = os.path.join(fold, '{0}_{1}.tsv'.format(l1, l2))\n",
    "        data = read_word_pairs_tsv(fn, id1, id2)\n",
    "        d_wps[lang_pair] = data\n",
    "\n",
    "d_dict = dict()\n",
    "for ((l1, l2), wp_l) in d_wps.items():\n",
    "    l12, l21 = wp_list_2_dict((l1, l2), wp_l)\n",
    "    d_dict[(l1, l2)] = l12\n",
    "    d_dict[(l2, l1)] = l21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('deu', 'eng'): {'hund': ['dog'],\n",
       "  'katze': ['cat'],\n",
       "  'mond': ['moon'],\n",
       "  'sonne': ['sun']},\n",
       " ('deu', 'hun'): {'hund': ['kutya'],\n",
       "  'katze': ['macska'],\n",
       "  'mond': ['hold'],\n",
       "  'sonne': ['nap']},\n",
       " ('eng', 'deu'): {'cat': ['katze'],\n",
       "  'dog': ['hund'],\n",
       "  'moon': ['mond'],\n",
       "  'sun': ['sonne']},\n",
       " ('eng', 'hun'): {'cat': ['macska'],\n",
       "  'dog': ['kutya'],\n",
       "  'moon': ['hold'],\n",
       "  'sun': ['nap']},\n",
       " ('hun', 'deu'): {'hold': ['mond'],\n",
       "  'kutya': ['hund'],\n",
       "  'macska': ['katze'],\n",
       "  'nap': ['sonne']},\n",
       " ('hun', 'eng'): {'hold': ['moon'],\n",
       "  'kutya': ['dog'],\n",
       "  'macska': ['cat'],\n",
       "  'nap': ['sun']}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_src_tr : source language translated embeddings\n",
    "# model_tar : target language embeddings\n",
    "# dict_scr_2_tar : dictionary from source to target\n",
    "def calc_precision(precs, model_src_tr, model_tar, dict_scr_2_tar, verbose=False):\n",
    "    W_src_tr = model_src_tr.syn0\n",
    "    W_tar = model_tar.syn0\n",
    "    idx_src_tr = model_src_tr.index2word\n",
    "    idx_tar = model_tar.index2word\n",
    "    \n",
    "    cos_mx = cosine_similarity(W_src_tr, W_tar)\n",
    "    sim_mx = np.argsort(-cos_mx)\n",
    "    max_prec = max(precs)\n",
    "    prec_cnt = np.zeros(shape=(1, max_prec))\n",
    "    if verbose:\n",
    "        print('word: \\ttranslations in dict: \\tclosest words after translation: \\t')\n",
    "    for i, r in enumerate(sim_mx):\n",
    "        key_word = idx_src_tr[i]\n",
    "        value_words = dict_scr_2_tar[key_word]\n",
    "        closest_words = []\n",
    "        for j in range(max_prec):       \n",
    "            ans = np.where(r==j)\n",
    "            idx_orig = ans[0][0]\n",
    "            word = idx_tar[idx_orig]\n",
    "            closest_words.append(word)\n",
    "            if word in value_words:\n",
    "                prec_cnt[0][j] = prec_cnt[0][j] + 1\n",
    "        if verbose:\n",
    "            print('{}\"\\t{}\\t{}'.format(key_word, value_words, closest_words))\n",
    "    if verbose:\n",
    "        print(prec_cnt)\n",
    "    prec_pcnts = []\n",
    "    for i, val in enumerate(precs):\n",
    "        sum_hit = np.sum(prec_cnt[0][0:val])\n",
    "        pcnt = float(sum_hit)/sim_mx.shape[0]\n",
    "        if verbose:\n",
    "            print('prec {} : {}'.format(val, pcnt))\n",
    "        prec_pcnts.append(pcnt)\n",
    "    return prec_pcnts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing precision calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: \ttranslations in dict: \tclosest words after translation: \t\n",
      "dog\"\t['hund']\t['mond']\n",
      "cat\"\t['katze']\t['mond']\n",
      "sun\"\t['sonne']\t['hund']\n",
      "moon\"\t['mond']\t['katze']\n",
      "[[ 0.]]\n",
      "prec 1 : 0.0\n",
      "word: \ttranslations in dict: \tclosest words after translation: \t\n",
      "dog\"\t['hund']\t['mond', 'hund']\n",
      "cat\"\t['katze']\t['mond', 'katze']\n",
      "sun\"\t['sonne']\t['hund', 'katze']\n",
      "moon\"\t['mond']\t['katze', 'hund']\n",
      "[[ 0.  2.]]\n",
      "prec 2 : 0.5\n",
      "word: \ttranslations in dict: \tclosest words after translation: \t\n",
      "dog\"\t['hund']\t['mond', 'hund', 'sonne']\n",
      "cat\"\t['katze']\t['mond', 'katze', 'sonne']\n",
      "sun\"\t['sonne']\t['hund', 'katze', 'sonne']\n",
      "moon\"\t['mond']\t['katze', 'hund', 'sonne']\n",
      "[[ 0.  2.  1.]]\n",
      "prec 3 : 0.75\n",
      "word: \ttranslations in dict: \tclosest words after translation: \t\n",
      "dog\"\t['hund']\t['mond', 'hund', 'sonne', 'katze']\n",
      "cat\"\t['katze']\t['mond', 'katze', 'sonne', 'hund']\n",
      "sun\"\t['sonne']\t['hund', 'katze', 'sonne', 'mond']\n",
      "moon\"\t['mond']\t['katze', 'hund', 'sonne', 'mond']\n",
      "[[ 0.  2.  1.  1.]]\n",
      "prec 4 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision without translation\n",
    "calc_precision([1], d_models['eng'], d_models['deu'], d_dict[('eng', 'deu')], verbose=True)\n",
    "calc_precision([2], d_models['eng'], d_models['deu'], d_dict[('eng', 'deu')], verbose=True)\n",
    "calc_precision([3], d_models['eng'], d_models['deu'], d_dict[('eng', 'deu')], verbose=True)\n",
    "calc_precision([4], d_models['eng'], d_models['deu'], d_dict[('eng', 'deu')], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langs : list containing sil codes of languages, tf_T follows the same order\n",
    "# d_models : dictionary, lang - embedding (KeyedVectors)\n",
    "# d_wps : dictiorary, lang_pair - wordpair list\n",
    "# dim : dimensiion of embedding\n",
    "# epochs : epochs to run\n",
    "# precs_to_calc : list of precisions to calculate, e.g. [1,3,5] if we want Precision @1, @3, @5\n",
    "# iters : optional, break after n update\n",
    "# lr : learning rate\n",
    "# svd : whether to do svd regularization\n",
    "# svd_f : how often regularize\n",
    "# verbose : print out details\n",
    "def train(langs, d_models, d_wps, dim, epochs, precs_to_calc, iters=None, lr=0.3, svd=False, svd_f=1, verbose=False):\n",
    "    nb_langs = len(langs)\n",
    "\n",
    "    # Init graphs\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # TF variables \n",
    "        # Placeholder for 2 words\n",
    "        tf_w1 = tf.placeholder(tf.float32, shape=[None, dim])\n",
    "        tf_w2 = tf.placeholder(tf.float32, shape=[None, dim])\n",
    "        # Placeholder for indexing the T matrix\n",
    "        tf_idx_l1 = tf.placeholder(tf.int32)\n",
    "        tf_idx_l2 = tf.placeholder(tf.int32)\n",
    "        # Translation matrices\n",
    "        tf_T = tf.Variable(tf.truncated_normal([nb_langs, dim, dim]))\n",
    "        \n",
    "        # SVD reguralization\n",
    "        tf_s1, tf_U1, tf_V1 = tf.svd(tf_T[tf_idx_l1], full_matrices=True, compute_uv=True)\n",
    "        updated_1 = tf.assign(tf_T[tf_idx_l1], tf.matmul(tf_U1, tf_V1))\n",
    "        tf_s2, tf_U2, tf_V2 = tf.svd(tf_T[tf_idx_l2], full_matrices=True, compute_uv=True)\n",
    "        updated_2 = tf.assign(tf_T[tf_idx_l2], tf.matmul(tf_U2, tf_V2))\n",
    "\n",
    "        # Loss\n",
    "        tf_T1 = tf.matmul(tf_w1, tf_T[tf_idx_l1])\n",
    "        tf_T2 = tf.matmul(tf_w2, tf_T[tf_idx_l2])\n",
    "        tf_T1_n = tf.nn.l2_normalize(tf_T1, dim=1)\n",
    "        tf_T2_n = tf.nn.l2_normalize(tf_T2, dim=1)\n",
    "        loss = tf.matmul(tf_T1_n, tf.transpose(tf_T2_n))\n",
    "        loss = -loss\n",
    "        \n",
    "        # Applying optimizer, Todo: try different optimizers!!\n",
    "        # https://www.tensorflow.org/api_guides/python/train#Optimizers \n",
    "        optimizer = tf.train.AdagradOptimizer(lr).minimize(loss)\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        j = 0\n",
    "        lc_arr = []\n",
    "        precs_arr = []\n",
    "        for i in range(epochs):\n",
    "            loss_arr = []\n",
    "            for ((l1, l2), wp_l) in d_wps.items():\n",
    "                loss_arr_l = []\n",
    "                idx_l1 = langs.index(l1)\n",
    "                idx_l2 = langs.index(l2)\n",
    "                k = 0\n",
    "                for (w1, w2) in wp_l:\n",
    "                    emb1 = d_models[l1][w1].reshape((1, 300))\n",
    "                    emb2 = d_models[l2][w2].reshape((1, 300))\n",
    "                    # Todo: if we add \"or j == 0\" for some reason it's better in this mock example\n",
    "                    if (svd and i % svd_f == 0) or j == 0:\n",
    "                        _, l, _, _, T = session.run([optimizer, loss, updated_1, updated_2, tf_T], \n",
    "                                                      feed_dict={tf_w1 : emb1, \n",
    "                                                                 tf_w2 : emb2, \n",
    "                                                                 tf_idx_l1 : idx_l1, \n",
    "                                                                 tf_idx_l2 : idx_l2})\n",
    "                    else:\n",
    "                        _, l, T = session.run([optimizer, loss, tf_T],\n",
    "                                             feed_dict={tf_w1 : emb1, \n",
    "                                                        tf_w2 : emb2, \n",
    "                                                        tf_idx_l1 : idx_l1, \n",
    "                                                        tf_idx_l2 : idx_l2})\n",
    "                    j += 1\n",
    "                    k += 1\n",
    "                    loss_arr.append(-l[0][0])\n",
    "                    loss_arr_l.append(-l[0][0])\n",
    "                    if iters is not None and j == iters:\n",
    "                        break\n",
    "                loss_np_arr_l = np.asarray(loss_arr_l)\n",
    "                if verbose:\n",
    "                    print('{0} - {1}\\tavg loss: {2}'.format(l1, l2, np.average(loss_np_arr_l)))\n",
    "                if iters is not None and j == iters:\n",
    "                    break\n",
    "                    \n",
    "            # Monitoring for learning curve\n",
    "            loss_np_arr = np.asarray(loss_arr)\n",
    "            loss_epoch_avg = np.average(loss_np_arr)\n",
    "            if verbose:\n",
    "                print('{0}\\tavg loss: {1}'.format(i, loss_epoch_avg))\n",
    "            lc_arr.append(loss_epoch_avg)\n",
    "            \n",
    "            # Calculate precision\n",
    "            e_prec_l = []\n",
    "            for ((l1, l2), _) in d_wps.items():\n",
    "                m1 = copy.deepcopy(d_models[l1])\n",
    "                m2 = copy.deepcopy(d_models[l2])\n",
    "                idx_l1 = langs.index(l1)\n",
    "                idx_l2 = langs.index(l2)\n",
    "                T1 = T[idx_l1]\n",
    "                T2 = T[idx_l2]\n",
    "                m1.syn0 = np.dot(m1.syn0, T1)\n",
    "                m2.syn0 = np.dot(m2.syn0, T2)\n",
    "                precs_1 = calc_precision(precs_to_calc, m1, m2, d_dict[(l1, l2)], verbose=False)\n",
    "                precs_2 = calc_precision(precs_to_calc, m2, m1, d_dict[(l2, l1)], verbose=False)\n",
    "                e_prec_l.append(((l1, l2), precs_1))\n",
    "                e_prec_l.append(((l2, l1), precs_2))\n",
    "            precs_arr.append(e_prec_l)\n",
    "    return T, lc_arr, precs_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('deu', 'eng'), [0.75, 1.0]), (('eng', 'deu'), [0.75, 1.0]), (('eng', 'hun'), [0.75, 1.0]), (('hun', 'eng'), [0.75, 1.0]), (('deu', 'hun'), [0.75, 1.0]), (('hun', 'deu'), [0.75, 1.0])]\n"
     ]
    }
   ],
   "source": [
    "T, lc, precs = train(langs, d_models, d_wps, 300, 20, [1, 2])\n",
    "print(precs[-1])\n",
    "# Check rank loss\n",
    "T1 = T[0]\n",
    "# print(np.linalg.svd(T1, compute_uv=False, full_matrices=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/H8CK4IAIWZ1igAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a17076198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display learning curve\n",
    "plt.plot(lc)\n",
    "plt.ylabel('avg cos sim over all train samples')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 0.6380517482757568), ('moon', 0.2543850839138031), ('sun', 0.1620684415102005)]\n",
      "[('cat', 0.5031781196594238), ('moon', 0.41951072216033936), ('sun', -0.45986729860305786)]\n"
     ]
    }
   ],
   "source": [
    "m1 = copy.deepcopy(d_models['eng'])\n",
    "m2 = copy.deepcopy(m1)\n",
    "\n",
    "W = copy.deepcopy(m2.syn0)\n",
    "T = np.random.rand(300,300)\n",
    "# print(W)\n",
    "# print(T)\n",
    "m2.syn0 = np.dot(W, T)\n",
    "# print(m2.syn0)\n",
    "print(m1.most_similar('dog'))\n",
    "print(m2.most_similar('dog'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
