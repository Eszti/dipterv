{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = 0\n",
    "langs_to_keep = ['eng', 'ita']\n",
    "\n",
    "out_fold = '/mnt/permanent/home/eszti/dipterv/panlex/data/panlex/tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "panlex_lite_path = \"/mnt/permanent/Language/Multi/Dic/Proj/EmergVocPanLex/panlex_lite/db.sqlite\"\n",
    "engine = create_engine('sqlite:///{0}'.format(panlex_lite_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lv\n",
      "reading ex\n",
      "reading dnx\n"
     ]
    }
   ],
   "source": [
    "print('reading lv')\n",
    "lv = pd.read_sql_table('lv', engine, index_col=\"lv\")\n",
    "print('reading ex')\n",
    "ex = pd.read_sql_table('ex', engine, index_col='ex')\n",
    "print('reading dnx')\n",
    "dnx = pd.read_sql_table('dnx', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_red = lv[lv.uid.isin(['{0}-000'.format(lang) for lang in langs_to_keep])]\n",
    "langids = lv_red.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnx_by_lang = {}\n",
    "ex_by_lang = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 187\n",
      "processing 304\n"
     ]
    }
   ],
   "source": [
    "for lang in langids:\n",
    "    print('processing {0}'.format(lang))\n",
    "    if lang not in ex_by_lang:\n",
    "        ex_by_lang[lang] = ex[ex.lv==lang]\n",
    "    if lang not in dnx_by_lang:\n",
    "        dnx_by_lang[lang] = dnx.merge(ex_by_lang[lang], left_on='ex', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will process these langs: ['eng', 'ita']\n",
      "doing eng-ita...\n",
      "all:  1130390\n",
      "len filtered:  1130390\n",
      "len unique:  661910\n",
      "writing eng-ita...\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "print('will process these langs: {0}'.format([lv.loc[lang]['uid'][:3] for lang in langids]))\n",
    "done = set()\n",
    "for lang1 in langids:\n",
    "    for lang2 in langids:\n",
    "        lang_pair = tuple(sorted([lang1, lang2]))\n",
    "        if lang1 == lang2 or lang_pair in done:\n",
    "            continue\n",
    "        done.add(lang_pair)\n",
    "        lang1_name = lv.loc[lang1]['uid'][:3]\n",
    "        lang2_name = lv.loc[lang2]['uid'][:3]\n",
    "        print('doing {0}-{1}...'.format(lang1_name, lang2_name))\n",
    "        ex1 = ex_by_lang[lang1]\n",
    "        ex2 = ex_by_lang[lang2]\n",
    "        dnx1 = dnx_by_lang[lang1]\n",
    "        dnx2 = dnx_by_lang[lang2]\n",
    "\n",
    "        tr = dnx1.merge(dnx2, on='mn')\n",
    "        tr['score'] = (tr['uq_x'] + tr['uq_y'])/2\n",
    "\n",
    "        filtered = tr[tr.score > min_score]\n",
    "        filtered_sorted = filtered.sort_values('score', ascending=False)\n",
    "        filtered_sorted_unique = filtered_sorted.drop_duplicates(subset=['tt_x', 'tt_y'])\n",
    "\n",
    "        print('all: ', len(tr))\n",
    "        print('len filtered: ', len(filtered))\n",
    "        print('len unique: ', len(filtered_sorted_unique))\n",
    "\n",
    "        print('writing {0}-{1}...'.format(lang1_name, lang2_name))\n",
    "        fn = os.path.join(out_fold, '{0}_{1}.tsv'.format(lang1_name, lang2_name))\n",
    "\n",
    "        with open(fn, 'wt') as f:\n",
    "            for _, row in filtered_sorted_unique.iterrows():\n",
    "                score = (row['uq_x'] + row['uq_y']) / 2\n",
    "                f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n\".format(\n",
    "                    lang1_name, lang2_name, row['tt_x'], row['tt_y'], score))\n",
    "        print('saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_unique_2 = filtered_sorted.drop_duplicates(subset=['tt_x', 'tt_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661910"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_unique_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
