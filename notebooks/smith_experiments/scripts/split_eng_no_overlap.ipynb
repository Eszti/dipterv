{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_emb = '/mnt/permanent/Language/Multi/FB/wiki.en/wiki.en.vec'\n",
    "ita_emb = '/mnt/permanent/Language/Multi/FB/wiki.it/wiki.it.vec'\n",
    "\n",
    "wp_folder = '/mnt/permanent/home/eszti/dipterv/panlex/data/smith/original/train'\n",
    "\n",
    "train_fn = 'train_eng_ita.tsv'\n",
    "valid_fn = 'valid_eng_ita.tsv'\n",
    "\n",
    "langs = ['eng', 'ita']\n",
    "idx1 = 0\n",
    "idx2 = 1\n",
    "eng = 'eng'\n",
    "ita = 'ita'\n",
    "\n",
    "limit = 350000\n",
    "tr_rat = 9 # tr_rat*10 % will be train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emb(emb_fn, limit):\n",
    "    model = KeyedVectors.load_word2vec_format(emb_fn, binary=False, limit=limit)\n",
    "    model.syn0 /= np.sqrt((model.syn0 ** 2).sum(1))[:, None]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_word_pairs_tsv(fn, id1, id2, header=True):\n",
    "    with open(fn) as f:\n",
    "        lines = f.readlines()\n",
    "        data = [(line.split()[id1], line.split()[id2]) for i, line in enumerate(lines) if i > 0 or header == False]\n",
    "    return data\n",
    "\n",
    "def get_word_pairs_dict(langs, wp_folder, idx1, idx2):\n",
    "    word_pairs_dict = dict()\n",
    "    done = set()\n",
    "    for lang1 in langs:\n",
    "        for lang2 in langs:\n",
    "            lang_pair = tuple(sorted([lang1, lang2]))\n",
    "            if lang1 == lang2 or lang_pair in done:\n",
    "                continue\n",
    "            done.add(lang_pair)\n",
    "            l1 = lang_pair[0]\n",
    "            l2 = lang_pair[1]\n",
    "            fn = os.path.join(wp_folder, '{0}_{1}.tsv'.format(l1, l2))\n",
    "            print('Reading word pair file: {0}'.format(fn))\n",
    "            data = read_word_pairs_tsv(fn, idx1, idx2, False)\n",
    "            word_pairs_dict[lang_pair] = data\n",
    "            print('Number of word pairs found: {0}'.format(len(data)))\n",
    "    return word_pairs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_found_list(vocab, embedding):\n",
    "    nf_list = []\n",
    "    for i, w in enumerate(vocab):\n",
    "        # Check if there's an embedding to the word\n",
    "        if w not in embedding:\n",
    "            nf_list.append(w)\n",
    "    return nf_list\n",
    "\n",
    "def wp_list_2_dict(wp_l):\n",
    "    l12 = dict()\n",
    "    l21 = dict()\n",
    "    for (w1, w2) in wp_l:\n",
    "        if w1 not in l12:\n",
    "            l12[w1] = [w2]\n",
    "        else:\n",
    "            l12[w1].append(w2)\n",
    "        if w2 not in l21:\n",
    "            l21[w2] = [w1]\n",
    "        else:\n",
    "            l21[w2].append(w1)\n",
    "    return l12, l21\n",
    "\n",
    "def get_two_lang_dictionaries(embeddings, word_pairs_dict):\n",
    "        dictionaries = dict()\n",
    "        updated_word_pairs = dict()\n",
    "        for ((l1, l2), wp_l) in word_pairs_dict.items():\n",
    "            print('Processing {0}-{1}...'.format(l1, l2))\n",
    "            # Find words without embeddings\n",
    "            [l1_vocab, l2_vocab] = zip( *wp_l)\n",
    "            l1_vocab = list(set(l1_vocab))\n",
    "            l2_vocab = list(set(l2_vocab))\n",
    "            print('Words in {0}: {1}'.format(l1, len(l1_vocab)))\n",
    "            print('Words in {0}: {1}'.format(l2, len(l2_vocab)))\n",
    "            nf_l1 = get_not_found_list(vocab=l1_vocab, embedding=embeddings[l1])\n",
    "            print('Words not found in embedding {0}: {1}'.format(l1, len(nf_l1)))\n",
    "            print(nf_l1)\n",
    "            nf_l2 = get_not_found_list(vocab=l2_vocab, embedding=embeddings[l2])\n",
    "            print('Words not found in embedding {0}: {1}'.format(l2, len(nf_l2)))\n",
    "            print(nf_l2)\n",
    "            # Update word list\n",
    "            print('Updating word pair list {0}-{1}'.format(l1, l2))\n",
    "            updated_wp_l = [(w1, w2) for (w1, w2) in wp_l if w1 not in nf_l1 and w2 not in nf_l2]\n",
    "            print('Word pairs list legth: {0} ->  {1} '.format(len(wp_l), len(updated_wp_l)))\n",
    "            updated_word_pairs[(l1, l2)] = updated_wp_l\n",
    "            # Create dictioary\n",
    "            print('Creating dictionary for: {0}-{1}'.format(l1, l2))\n",
    "            l12, l21 = wp_list_2_dict(updated_wp_l)\n",
    "            dictionaries[(l1, l2)] = l12\n",
    "            dictionaries[(l2, l1)] = l21\n",
    "            print('# word in: {0}-{1}:\\t{2}'.format(l1.upper(), l2, len(l12)))\n",
    "            print('# word in: {0}-{1}:\\t{2}'.format(l2.upper(), l1, len(l21)))\n",
    "        return dictionaries, updated_word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_en = read_emb(eng_emb, limit)\n",
    "m_it = read_emb(ita_emb, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading word pair file: /mnt/permanent/home/eszti/dipterv/panlex/data/smith/original/train/eng_ita.tsv\n",
      "Number of word pairs found: 5000\n"
     ]
    }
   ],
   "source": [
    "word_pairs_dict = get_word_pairs_dict(langs, wp_folder, idx1, idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eng-ita...\n",
      "Words in eng: 3442\n",
      "Words in ita: 4549\n",
      "Words not found in embedding eng: 0\n",
      "[]\n",
      "Words not found in embedding ita: 1\n",
      "['prelaurea']\n",
      "Updating word pair list eng-ita\n",
      "Word pairs list legth: 5000 ->  4999 \n",
      "Creating dictionary for: eng-ita\n",
      "# word in: ENG-ita:\t3442\n",
      "# word in: ITA-eng:\t4548\n"
     ]
    }
   ],
   "source": [
    "embeddings = dict()\n",
    "embeddings[eng] = m_en\n",
    "embeddings[ita] = m_it\n",
    "\n",
    "dictionaries, updated_word_pairs = get_two_lang_dictionaries(embeddings, word_pairs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dictionaries):\n",
    "    i = 0\n",
    "    tr = []\n",
    "    val = []\n",
    "    for (k, vals) in dictionaries[(eng, ita)].items():\n",
    "        wp_s = []\n",
    "        for v in vals:\n",
    "            wp_s.append((k, v))\n",
    "        if i % 10 < tr_rat:\n",
    "            tr += wp_s\n",
    "        else:\n",
    "            val += wp_s\n",
    "        i += 1\n",
    "    return tr, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wps, valid_wps = split(dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4498"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_wps)\n",
    "len(valid_wps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wlists(wps):\n",
    "    wl1 = set()\n",
    "    wl2 = set()\n",
    "    for (w1, w2) in wps:\n",
    "        wl1.add(w1)\n",
    "        wl2.add(w2)\n",
    "    return wl1, wl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3098"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4129"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_en, tr_it = get_wlists(train_wps)\n",
    "va_en, va_it = get_wlists(valid_wps)\n",
    "\n",
    "len(tr_en)\n",
    "len(tr_it)\n",
    "len(va_en)\n",
    "len(va_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_en = set(tr_en) & set(va_en)\n",
    "overlap_it = set(tr_it) & set(va_it)\n",
    "len(overlap_en)\n",
    "len(overlap_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_list_2_dict(wp_l):\n",
    "    l12 = dict()\n",
    "    l21 = dict()\n",
    "    for (w1, w2) in wp_l:\n",
    "        if w1 not in l12:\n",
    "            l12[w1] = [w2]\n",
    "        else:\n",
    "            l12[w1].append(w2)\n",
    "        if w2 not in l21:\n",
    "            l21[w2] = [w1]\n",
    "        else:\n",
    "            l21[w2].append(w1)\n",
    "    return l12, l21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_en_it, tr_it_en = wp_list_2_dict(train_wps)\n",
    "va_en_it, va_it_en = wp_list_2_dict(valid_wps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vendita\n",
      "train: ['sale', 'sales']\n",
      "test: ['selling']\n",
      "ogni\n",
      "train: ['every', 'any']\n",
      "test: ['each']\n",
      "voto\n",
      "train: ['voting']\n",
      "test: ['vote']\n",
      "contatti\n",
      "train: ['contacts']\n",
      "test: ['contact']\n",
      "quota\n",
      "train: ['proportion']\n",
      "test: ['share']\n",
      "vendere\n",
      "train: ['sell']\n",
      "test: ['selling']\n",
      "porta\n",
      "train: ['brings', 'door']\n",
      "test: ['leads']\n",
      "migliore\n",
      "train: ['better']\n",
      "test: ['best']\n",
      "morte\n",
      "train: ['kill']\n",
      "test: ['death']\n",
      "membri\n",
      "train: ['members']\n",
      "test: ['member']\n",
      "animali\n",
      "train: ['animals']\n",
      "test: ['animal']\n",
      "ferroviario\n",
      "train: ['railway']\n",
      "test: ['rail']\n",
      "dettagli\n",
      "train: ['detail']\n",
      "test: ['details']\n",
      "ramo\n",
      "train: ['arm']\n",
      "test: ['branch']\n",
      "maggiore\n",
      "train: ['greater']\n",
      "test: ['increased']\n",
      "aula\n",
      "train: ['chamber']\n",
      "test: ['house']\n",
      "ascolto\n",
      "train: ['listen']\n",
      "test: ['listening']\n",
      "importo\n",
      "train: ['amount']\n",
      "test: ['sum']\n",
      "assemblea\n",
      "train: ['assembly']\n",
      "test: ['house']\n",
      "carriera\n",
      "train: ['career']\n",
      "test: ['careers']\n",
      "ultimi\n",
      "train: ['recent']\n",
      "test: ['last']\n",
      "discussione\n",
      "train: ['discussion']\n",
      "test: ['debate']\n",
      "promozione\n",
      "train: ['promotion']\n",
      "test: ['promoting']\n",
      "comuni\n",
      "train: ['common']\n",
      "test: ['commons']\n",
      "istituzione\n",
      "train: ['establishment']\n",
      "test: ['institution']\n",
      "applicazione\n",
      "train: ['application']\n",
      "test: ['implementation']\n",
      "rapporti\n",
      "train: ['relationship']\n",
      "test: ['relations']\n",
      "meglio\n",
      "train: ['better']\n",
      "test: ['best']\n",
      "sacre\n",
      "train: ['holy']\n",
      "test: ['sacred']\n",
      "vincere\n",
      "train: ['winning']\n",
      "test: ['win']\n",
      "osservazioni\n",
      "train: ['comments']\n",
      "test: ['observations']\n",
      "segnale\n",
      "train: ['sign']\n",
      "test: ['signal']\n",
      "quantità\n",
      "train: ['amount']\n",
      "test: ['quantity']\n",
      "impresa\n",
      "train: ['company', 'enterprise']\n",
      "test: ['undertaking']\n",
      "perdere\n",
      "train: ['losing']\n",
      "test: ['lose']\n",
      "unità\n",
      "train: ['unity', 'units']\n",
      "test: ['unit']\n",
      "soldato\n",
      "train: ['soldier']\n",
      "test: ['bronze']\n",
      "marchio\n",
      "train: ['label']\n",
      "test: ['mark']\n",
      "droga\n",
      "train: ['drug']\n",
      "test: ['drugs']\n",
      "ultima\n",
      "train: ['final']\n",
      "test: ['last']\n",
      "appello\n",
      "train: ['call']\n",
      "test: ['appeal']\n",
      "contribuire\n",
      "train: ['help']\n",
      "test: ['contribute']\n",
      "rispondere\n",
      "train: ['answer']\n",
      "test: ['respond']\n",
      "questione\n",
      "train: ['matter', 'question']\n",
      "test: ['issue']\n",
      "professionali\n",
      "train: ['professional']\n",
      "test: ['occupational']\n",
      "bar\n",
      "train: ['bars']\n",
      "test: ['bar']\n",
      "tenendo\n",
      "train: ['bearing']\n",
      "test: ['taking']\n",
      "cristiani\n",
      "train: ['christian']\n",
      "test: ['christians']\n",
      "editori\n",
      "train: ['editors']\n",
      "test: ['publishers']\n",
      "controllato\n",
      "train: ['controlled']\n",
      "test: ['checked']\n",
      "regolamentazione\n",
      "train: ['regulatory']\n",
      "test: ['regulation']\n",
      "sale\n",
      "train: ['rooms']\n",
      "test: ['salt']\n",
      "regolamento\n",
      "train: ['rules', 'procedure']\n",
      "test: ['regulation']\n",
      "circa\n",
      "train: ['approximately']\n",
      "test: ['around']\n",
      "relazioni\n",
      "train: ['reports']\n",
      "test: ['relations']\n",
      "responsabilità\n",
      "train: ['responsibility']\n",
      "test: ['producer']\n",
      "meno\n",
      "train: ['main']\n",
      "test: ['less']\n",
      "parità\n",
      "train: ['equal']\n",
      "test: ['equality']\n",
      "accessibili\n",
      "train: ['accessible']\n",
      "test: ['affordable']\n",
      "migliori\n",
      "train: ['better']\n",
      "test: ['best']\n",
      "iniziato\n",
      "train: ['began', 'begun']\n",
      "test: ['started']\n",
      "fondamentali\n",
      "train: ['basic']\n",
      "test: ['fundamental']\n",
      "evitare\n",
      "train: ['prevent']\n",
      "test: ['avoid']\n",
      "vita\n",
      "train: ['lives', 'life']\n",
      "test: ['living']\n",
      "promuovere\n",
      "train: ['promote']\n",
      "test: ['promoting']\n",
      "primo\n",
      "train: ['first']\n",
      "test: ['prime']\n",
      "questioni\n",
      "train: ['questions', 'issues']\n",
      "test: ['matters']\n",
      "foto\n",
      "train: ['photographs', 'photo']\n",
      "test: ['photos']\n",
      "acquistare\n",
      "train: ['purchase']\n",
      "test: ['buy']\n",
      "costi\n",
      "train: ['cost']\n",
      "test: ['costs']\n",
      "fondamentale\n",
      "train: ['essential']\n",
      "test: ['fundamental']\n",
      "filo\n",
      "train: ['thread']\n",
      "test: ['wire']\n",
      "fotografie\n",
      "train: ['photographs']\n",
      "test: ['photos']\n",
      "organizzazione\n",
      "train: ['organization']\n",
      "test: ['organisation']\n",
      "casa\n",
      "train: ['home']\n",
      "test: ['house']\n",
      "contenuti\n",
      "train: ['content']\n",
      "test: ['contained']\n",
      "identificare\n",
      "train: ['identifying']\n",
      "test: ['identify']\n",
      "cattura\n",
      "train: ['capture']\n",
      "test: ['catch']\n",
      "produttore\n",
      "train: ['manufacturer']\n",
      "test: ['producer']\n",
      "ali\n",
      "train: ['wings']\n",
      "test: ['ali']\n",
      "fatal: 0\n"
     ]
    }
   ],
   "source": [
    "fatal = 0\n",
    "for w in overlap_it:\n",
    "    print(w)\n",
    "    w_tr = tr_it_en[w]\n",
    "    w_va = va_it_en[w]\n",
    "    if w_tr == w_va:\n",
    "        fatal += 1\n",
    "    print('train: {}'.format(w_tr))\n",
    "    print('test: {}'.format(w_va))\n",
    "    \n",
    "print('fatal: {}'.format(fatal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fn, wp_l):\n",
    "    with open(fn, 'wt') as f:\n",
    "        wr = csv.writer(f, dialect='excel', delimiter='\\t')\n",
    "        wr.writerows(wp_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(train_fn, train_wps)\n",
    "save(valid_fn, valid_wps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
